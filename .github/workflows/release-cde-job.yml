name: Release CDE Job

on:
  workflow_call:
    inputs:
      manage-resource:
        description: 'Decide to create or update resource'
        default: true
        required: false
        type: boolean
      resource-name:
        description: 'CDE Resource Name'
        default: ''
        required: true
        type: string
      job-name:
        description: 'CDE Job Name'
        default: ''
        required: true
        type: string
      vcluster-endpoint:
        description: 'Virtual Cluster Endpoint'
        required: true
        default: ''
        type: string
      application-file:
        description: 'Application file name'
        default: ''
        required: true
        type: string
      files:
        description: 'Additionals files'
        default: ''
        required: false
        type: string
      driver-cores:
        description: 'Enter driver cores'
        default: ''
        required: false
        type: string
      driver-memory:
        description: 'Enter driver memory'
        default: ''
        required: false
        type: string
      executor-cores:
        description: 'Enter executor cores'
        default: ''
        required: false
        type: string
      executor-memory:
        description: 'Enter executor memory'
        default: ''
        required: false
        type: string
      jars:
        description: 'Enter jar'
        default: ''
        required: false
        type: string
      packages:
        description: 'Enter package'
        default: ''
        required: false
        type: string
      repositories:
        description: 'Enter repositories'
        default: ''
        required: false
        type: string
      additional-args:
        description: 'Additional job arguments (e.g., "--arg timeout --arg 30")'
        default: ''
        required: false
        type: string
      additional-conf:
        description: 'Additional job confs (e.g., "--conf conf_name)'
        default: ''
        required: false
        type: string
      working-dir:
        description: 'working directory'
        default: ''
        required: true
        type: string

jobs:
  create-runner:
    name: Create Runner
    if: github.ref_type == 'branch'
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Create Runner
        id: create-runner
        uses: pagopa/pdnd-github-actions/deploy-eks-gh-runner@7fb09afd4227db40789da70cbdaa2c7157abff49
        with:
          name: ${{ github.event.repository.name }}
          cluster_name: ${{ vars.RUNNER_CLUSTER_NAME }}
          aws_runner_deploy_role: ${{ secrets.AWS_RUNNER_DEPLOY_ROLE }}
          namespace: ${{ vars.RUNNER_K8S_NAMESPACE }}
          image: ${{ vars.RUNNER_DOCKER_IMAGE}}
          service_account: ${{ vars.RUNNER_SERVICE_ACCOUNT }}        
          docker_enabled: true
    outputs:
      runner_label: ${{ steps.create-runner.outputs.runner_label }}
  login-poetry:
    name: Login Poetry
    runs-on: [self-hosted, "${{ needs.create-runner.outputs.runner_label }}"]
    needs:
      - create-runner
    steps:
      - id : login-poetry
        run : |
            echo "POETRY_HTTP_BASIC_ARTIFACT_PASSWORD=$(aws codeartifact get-authorization-token --domain-owner ${{ secrets.AWS_ACCOUNT_ID }} \
              --domain ${{ vars.CODEARTIFACT_DOMAIN }} --query 'authorizationToken' --output text)" >> "$GITHUB_OUTPUT"
      - id : login-ecr
        run : |
            echo "ECR_PASSWORD=$(aws ecr get-login-password --region eu-central-1)" >> "$GITHUB_OUTPUT"
    outputs:
      poetry_token: ${{ steps.login-poetry.outputs.POETRY_HTTP_BASIC_ARTIFACT_PASSWORD }}
      docker_password: ${{ steps.login-ecr.outputs.ECR_PASSWORD }}
  build-venv:
    name: Build Env
    needs:
      - create-runner
      - login-poetry 
    runs-on: [self-hosted, "${{ needs.create-runner.outputs.runner_label }}"]
    container:
      image: ${{ vars.CDE_RUNTIME_IMAGE }}
      credentials:
        username: AWS
        password: ${{ needs.login-poetry.outputs.docker_password }}
      options: 
        --privileged
        --user root
      env:
        POETRY_HTTP_BASIC_ARTIFACT_PASSWORD: ${{ needs.login-poetry.outputs.poetry_token }}
    env:
      POETRY_HTTP_BASIC_ARTIFACT_PASSWORD: ${{ needs.login-poetry.outputs.poetry_token }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Build Project
        continue-on-error: false
        working-directory: ${{ inputs.working-dir }}
        run: |
          poetry config virtualenvs.in-project true
          poetry config virtualenvs.create true
          export POETRY_HTTP_BASIC_ARTIFACT_USERNAME=aws
          #poetry lock --no-update
          poetry install --without test,dev --no-root
          poetry build -f wheel -n 
          poetry run pip install --no-deps dist/*.whl
          poetry run pip install venv-pack2
          poetry run venv-pack -o ${{ inputs.job-name }}.tar.gz
      - name: Upload Build Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-artifact
          path: ${{ inputs.working-dir }}/${{ inputs.job-name }}.tar.gz
          overwrite: true
  release:
    name: Release
    runs-on: [self-hosted, "${{ needs.create-runner.outputs.runner_label }}"]
    needs:
      - create-runner
      - login-poetry
      - build-venv
    outputs:
      version: ${{ steps.release.outputs.tag }}
    if: needs.build-venv.result == 'success'
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Final Semantic Release
        uses: python-semantic-release/python-semantic-release@18399a7209118c6f0bcc923857ef7052cc5de5e3 # V9.10.0
        id: release
        with:
          directory: ${{ inputs.working-dir }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          commit: "true"
          push: "true"
          tag: "true"
      - name: Check Calculated Version Output
        run: |
          echo "New Release Version: ${{ steps.release.outputs.tag }}"
  deploy:
    name: Deploy
    runs-on: [self-hosted, "${{ needs.create-runner.outputs.runner_label }}"]
    env:
      VERSION: ${{ needs.release.outputs.version }}
    needs:
      - create-runner
      - login-poetry
      - build-venv
      - release
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: build-artifact
          path: ${{ inputs.working-dir }}  
      - name: Setup CDE CLI
        uses: pagopa/pdnd-github-actions/setup-cde-cli@6b1d8bd54b81bb92959959fe83ccda30aa6ff0bd
        with:
          version: "1.20.3"
          access_key_id: ${{ secrets.GH_CDP_ACCESS_KEY_ID }}
          private_key: ${{ secrets.GH_CDP_PRIVATE_KEY }}
          codeartifact_domain: ${{ vars.CODEARTIFACT_DOMAIN }}
          codeartifact_repository: ${{ vars.CODEARTIFACT_REPOSITORY }}
          vcluster_endpoint: ${{ inputs.vcluster-endpoint }}
      - name: Check and Create Resource if not exists
        if: ${{ inputs.manage-resource }}
        run: |
          RESOURCE_NAME="${{ inputs.resource-name }}"
          # Check if the resource exists
          if ! cde resource describe --name "$RESOURCE_NAME" >/dev/null 2>&1; then
            echo -e "\033[1;31m🚨 Resource '$RESOURCE_NAME' does not exist. Creating...\033[0m"
            cde resource create --name "$RESOURCE_NAME" --type files
            echo -e "\033[1;32m✅ Resource '$RESOURCE_NAME' created successfully.\033[0m"
          else
            echo -e "\033[1;34mℹ️  Resource '$RESOURCE_NAME' already exists.\033[0m"
          fi
      - name: Upload Resources
        if: ${{ inputs.manage-resource }}
        working-directory: ${{ inputs.working-dir }}   
        run: |
          #Update Version
          echo "${{ env.VERSION }}" > version.txt
          cde resource upload --name ${{ inputs.resource-name }} --local-path version.txt
          cde resource upload --name ${{ inputs.resource-name }} --local-path ${{ inputs.job-name }}.tar.gz
          cde resource upload --name ${{ inputs.resource-name }} --local-path src/pdnd_${{ inputs.job-name }}/${{ inputs.application-file }}
          # Check if there are additional files; if so, upload them as resources
          ##if [ -n "${{ inputs.files }}" ]; then
          ##  for file in $(echo ${{ inputs.files }} | tr ',' '\n'); do
          ##    cde resource upload --name ${{ inputs.resource-name }} --local-path $file
          ##  done
          ##fi
          if [ -n "${{ inputs.files }}" ]; then
          for file in $(echo ${{ inputs.files }} | tr ',' '\n'); do
            # Remove the 'src/<module>/' part from the file path
            destination_path=$(echo "$file" | sed -E 's#src/[^/]+##')
            cde resource upload --name ${{ inputs.resource-name }} --local-path "$file" --resource-path "$destination_path"
            done
          fi
      - name: Create or Update Spark Job on CDE
        working-directory: ${{ inputs.working-dir }}  
        run: |
          # Initialize the array for optional arguments
          ADDITIONAL_ARGS=()
          # Function to add optional arguments if not empty
          add_optional_arg() {
            local arg_name=$1
            local arg_value=$2
            if [ -n "$arg_value" ]; then
              ADDITIONAL_ARGS+=("$arg_name" "$arg_value")
            fi
          }
          # Add optional parameters
          add_optional_arg "--driver-cores" "${{ inputs.driver-cores }}"
          add_optional_arg "--driver-memory" "${{ inputs.driver-memory }}"
          add_optional_arg "--executor-cores" "${{ inputs.executor-cores }}"
          add_optional_arg "--executor-memory" "${{ inputs.executor-memory }}"
          add_optional_arg "--jars" "${{ inputs.jars }}"
          add_optional_arg "--packages" "${{ inputs.packages }}"
          add_optional_arg "--repositories" "${{ inputs.repositories }}"
          # Add additional-args
          if [ -n "${{ inputs.additional-args }}" ]; then
            ADDITIONAL_ARGS+=("${{ inputs.additional-args }}")
          fi
          # Add additional-conf
          if [ -n "${{ inputs.additional-conf }}" ]; then
            ADDITIONAL_ARGS+=("${{ inputs.additional-conf }}")
          fi
          # Extract file names from the path to add to the --files parameter
          ##FILE_NAMES=$(echo ${{ inputs.files }} | xargs -n 1 basename | tr '\n' ',' | sed 's/,$//')
          ##FILE_NAMES=$(echo "${{ inputs.files }}" | tr ',' '\n' | xargs -n 1 basename | paste -sd ',' -)
          ##echo $FILE_NAMES
          ##add_optional_arg "--files" "$FILE_NAMES"
          # Upload files with their original path
          if [ -n "${{ inputs.files }}" ]; then
          for file in $(echo ${{ inputs.files }} | tr ',' '\n'); do
            # Remove the 'src/<module>/' part from the file path
            destination_path=$(echo "$file" | sed -E 's#src/[^/]+/##')
            # Perform the upload by reconstructing the correct path
            add_optional_arg "--files" "$destination_path"
            done
          fi
          # Extract the names of the jobs present in CDE
          JOB_NAMES=$(cde job list | jq -r '.[].name')
          echo -e "🔍 \033[1;34mJob names founded:\033[0m\n"
          for job in $(echo "$JOB_NAMES" | tr ' ' '\n'); do
            echo -e "  ➤ \033[1;32m$job\033[0m"
          done
          # Controlla se il job esiste
          if echo "$JOB_NAMES" | grep -Fxq "${{ inputs.job-name }}"; then
            echo -e "\nThe job \033[1;32m "${{ inputs.job-name }}"\033[0m already exists, updating it..."
            ACTION="update"
          else
            echo "The job does not exist, creating it..."
            ACTION="create --type spark"
          fi
          # Define the common command
          CDE_COMMAND=(
            "cde job $ACTION"
            "--name" "${{ inputs.job-name }}"
            "--mount-1-resource" "${{ inputs.resource-name }}"
            "--application-file" "${{ inputs.application-file }}"
            "--file" "${{ inputs.job-name }}.tar.gz"
            "--runtime-image-resource-name" "${{ vars.RUNTIME_IMAGE_RESOURCE_NAME }}"
            "--conf" "spark.archives=/app/mount/${{ inputs.job-name }}.tar.gz#environment"
            "--conf" "spark.pyspark.python=/opt/spark/work-dir/./environment/bin/python3"
            "--arg" "--knox_config.gateway"
            "--arg" "${{ vars.KNOX_GATEWAY }}"
            "--arg" "--knox_config.hostname"
            "--arg" "${{ vars.KNOX_HOSTNAME }}"
            "${ADDITIONAL_ARGS[@]}"
          )
          # Build the final command
          FINAL_COMMAND="${CDE_COMMAND[@]}"
          echo "Executing command: $FINAL_COMMAND"
          eval "$FINAL_COMMAND"
          echo "Job completed with success."
      - name: Slack Notification
        uses: ravsamhq/notify-slack-action@master
        if: always()
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          status: ${{ job.status }}
          notification_title: "{workflow} has {status_message}"
          message_format: "{emoji} *{workflow}* <https://github.com/{repo}/actions/runs/${{ github.run_id }}|${{github.ref_name}}> {status_message} in <{repo_url}|{repo}>"
          footer: "<{repo_url}|Repo> | <{workflow_url}|Workflow>"
          notify_when: "success,failure,warnings"
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
  destroy_runner:
    name: Destroy Runner
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    if: ${{ always() && !contains(needs.create-runner.result, 'failure')}}
    needs:
      - create-runner
      - login-poetry
      - build-venv
      - release
      - deploy
    steps:
      - name: Destroy Runner
        id: destroy_runner
        uses: pagopa/pdnd-github-actions/undeploy-eks-gh-runner@7fb09afd4227db40789da70cbdaa2c7157abff49
        with:
          cluster_name: ${{ vars.RUNNER_CLUSTER_NAME }}
          aws_runner_deploy_role: ${{ secrets.AWS_RUNNER_DEPLOY_ROLE }}
          runner_label: ${{ needs.create-runner.outputs.runner_label }}
          namespace:  ${{ vars.RUNNER_K8S_NAMESPACE }}